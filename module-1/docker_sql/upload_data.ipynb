{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434fb88e-8ba5-417a-b414-d13cf78f9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6dc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a connection to postgres to run the DDL command to create the table for the taxi data\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a305fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e63a4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet = pq.ParquetFile('yellow_tripdata_2021-01.parquet')\n",
    "pq_iter = parquet.iter_batches(batch_size=100000)\n",
    "df = next(pq_iter).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be1554e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will load the data into the database in chunks because there is a large number of records\n",
    "# we can get an iterator from the read_csv function by passing true to the iterator arg.\n",
    "# df_iter = pd.read_csv('yellow_tripdata_2021-01.csv', iterator=True, chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76b1eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155277f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pickup and dropoff times to datetime type\n",
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aa04e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9caa1145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the to_sql function inserts the data in the df into the database. \n",
    "# if we execute this function on df.head(n=0) then it will only create the table but not insert any data\n",
    "df.head(n=0).to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')\n",
    "df.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4706eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37a5dae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added another chunk... took 44.653727293014526 seconds\n",
      "added another chunk... took 41.50014305114746 seconds\n",
      "added another chunk... took 40.89141654968262 seconds\n",
      "added another chunk... took 41.45792841911316 seconds\n",
      "added another chunk... took 40.8248405456543 seconds\n",
      "added another chunk... took 45.357142210006714 seconds\n",
      "added another chunk... took 42.441200256347656 seconds\n",
      "added another chunk... took 44.165322065353394 seconds\n",
      "added another chunk... took 46.21643948554993 seconds\n",
      "added another chunk... took 41.49136257171631 seconds\n",
      "added another chunk... took 46.15007257461548 seconds\n",
      "added another chunk... took 38.982813119888306 seconds\n",
      "added another chunk... took 26.695496797561646 seconds\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m t_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# get next chunk\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(pq_iter)\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#convert pickup and dropoff times to datetime type\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mtpep_pickup_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mtpep_pickup_datetime)\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# code to insert data chunkwise\n",
    "while True:\n",
    "    \n",
    "    t_start = time()\n",
    "    \n",
    "    # get next chunk\n",
    "    df = next(pq_iter).to_pandas()\n",
    "    \n",
    "    #convert pickup and dropoff times to datetime type\n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    \n",
    "    df.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')\n",
    "    \n",
    "    \n",
    "    t_end = time()\n",
    "    print(f\"added another chunk... took {t_end - t_start} seconds\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
